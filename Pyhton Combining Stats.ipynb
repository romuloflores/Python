{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97b49821",
   "metadata": {},
   "source": [
    "# Library and Root setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "338acc39",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "#SQL Folder root\n",
    "rootdir = \"C:\\\\Users\\\\Admin\\\\OneDrive - Bytedance\\\\R1 APAC - Quality\\\\Raw Data\\\\Productivity\"\n",
    "\n",
    "\n",
    "#Standard files root\n",
    "teamcode_rootdir = 'C:\\\\Users\\\\Admin\\\\OneDrive - Bytedance\\\\R1 APAC - Quality\\\\PowerBI\\\\Team code.xlsx'\n",
    "queues_rootdir = 'C:\\\\Users\\\\Admin\\\\OneDrive - Bytedance\\\\R1 APAC - Quality\\\\PowerBI\\\\Queues - Raw Data.xlsx'\n",
    "\n",
    "\n",
    "#Extraction files root\n",
    "sql_rootdir = 'C:\\\\Users\\\\Admin\\\\OneDrive - Bytedance\\\\R1 APAC - Quality\\\\Processed Data\\\\SQL - Raw Data.xlsx'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d011b4b",
   "metadata": {},
   "source": [
    "# Combining files and Spotcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c4125c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\OneDrive - Bytedance\\R1 APAC - Quality\\Raw Data\\Productivity\\Test files\\Claimant file.xlsx    --- Not a SQL file\n",
      "C:\\Users\\Admin\\OneDrive - Bytedance\\R1 APAC - Quality\\Raw Data\\Productivity\\Test files\\Empty file test.xlsx    --- File is empty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_10456\\3755396959.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_xlsx = combined_xlsx.append(exce_file, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_10456\\3755396959.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_xlsx = combined_xlsx.append(exce_file, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_10456\\3755396959.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_xlsx = combined_xlsx.append(exce_file, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_10456\\3755396959.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_xlsx = combined_xlsx.append(exce_file, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_10456\\3755396959.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_xlsx = combined_xlsx.append(exce_file, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_10456\\3755396959.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_xlsx = combined_xlsx.append(exce_file, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_10456\\3755396959.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_xlsx = combined_xlsx.append(exce_file, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_10456\\3755396959.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_xlsx = combined_xlsx.append(exce_file, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_10456\\3755396959.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_xlsx = combined_xlsx.append(exce_file, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1083 entries, 0 to 1082\n",
      "Data columns (total 7 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   index                       1083 non-null   int64  \n",
      " 1   Date                        1083 non-null   object \n",
      " 2   QA Name                     1083 non-null   object \n",
      " 3   Sampling Queue ID           1083 non-null   int64  \n",
      " 4   Sampling Queue Title        1083 non-null   object \n",
      " 5   QA Total Handling Time (s)  1083 non-null   float64\n",
      " 6   No. of QA Tasks             1083 non-null   int64  \n",
      "dtypes: float64(1), int64(3), object(3)\n",
      "memory usage: 59.4+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_10456\\3755396959.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_xlsx = combined_xlsx.append(exce_file, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "### Extracting file paths\n",
    "all_filenames = []\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        all_filenames.append(os.path.join(subdir, file))\n",
    "\n",
    "### Creating empty Dataframes\n",
    "combined_xlsx = pd.DataFrame() #Empty Dataframe\n",
    "combined_csv = pd.DataFrame() #Empty Dataframe \n",
    "\n",
    "### Looping through files\n",
    "for file in all_filenames:\n",
    "\n",
    "    ### xlsx files\n",
    "    if file.endswith('.xlsx'):\n",
    "        exce_file= pd.concat(pd.read_excel(file ,sheet_name=None), ignore_index = True)\n",
    "        \n",
    "        ### Controlling Empty files\n",
    "        if exce_file.empty:\n",
    "            print(file, '   --- File is empty')\n",
    "            continue\n",
    "        \n",
    "        ### Controlling SQL file structure\n",
    "        elif 'QA Total Handling Time (s)' not in exce_file.columns:\n",
    "            print(file, \"   --- Not a SQL file\")\n",
    "            continue\n",
    "            \n",
    "        ### Combining xlsx files\n",
    "        elif \"QA Total Handling Time (s)\" in exce_file.columns: \n",
    "            combined_xlsx = combined_xlsx.append(exce_file, ignore_index=True)\n",
    "\n",
    "    ### csv files\n",
    "    elif file.endswith('.csv'):\n",
    "        csv_file= pd.read_csv(file, encoding= 'unicode_escape')\n",
    "        \n",
    "        ### Controlling Empty files       \n",
    "        if csv_file.empty:\n",
    "            print(file, '   --- File is empty')\n",
    "            continue\n",
    "            \n",
    "        ### Controlling SQL file structure. \n",
    "        elif \"QA Total Handling Time (s)\" not in csv_file:\n",
    "            print(file, \"   --- Not a SQL file\")\n",
    "            continue\n",
    "            \n",
    "        ### Combining csv files\n",
    "        elif \"QA Total Handling Time (s)\" in csv_file.columns: \n",
    "            combined_csv = combined_csv.append(csv_file, ignore_index=True)\n",
    "\n",
    "    else:\n",
    "        ### Controlling file extension.\n",
    "        print(file, '   ---Not an Excel file')\n",
    "\n",
    "### Combining dataframes\n",
    "combined_all = pd.concat([combined_xlsx, combined_csv], ignore_index=True)\n",
    "combined_all = combined_all.reset_index()\n",
    "print(\"\\n\")\n",
    "combined_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a97d827",
   "metadata": {},
   "source": [
    "# Renaming Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3567cfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combined_all.rename(columns = {'No. of QA Tasks': 'object_id'\n",
    "                               ,'QA Name': 'QA_Name'\n",
    "                               ,'QA Total Handling Time (s)': 'Handling_Time'\n",
    "                               ,'Sampling Queue Title':'Queue_Name'\n",
    "                               ,'Sampling Queue ID':'project_id'\n",
    "                              }).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b1bee9",
   "metadata": {},
   "source": [
    "# Calculating and Adding WeekEnding column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01c872ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I must add the data range as August Week 3 otherwise it will update with the first value that meets the conditions. \n",
    "ls = []\n",
    "for i in df['Date']:\n",
    "    d = str(i).split('-')\n",
    "        \n",
    "      #2022\n",
    "    if int(d[0])== 2022:\n",
    "        \n",
    "         #January\n",
    "        if int(d[1]) == 1:\n",
    "            if (int(d[2]) >= 1 and int(d[2]) <= 2):  #Jan week 1\n",
    "                ls.append('2022-01-02')\n",
    "            elif (int(d[2]) >= 3 and int(d[2]) <= 9):  #Jan week 2\n",
    "                ls.append('2022-01-09')\n",
    "            elif  (int(d[2]) >= 10 and int(d[2]) <= 16):  #Jan week 3\n",
    "                ls.append('2022-01-16')\n",
    "            elif (int(d[2]) >= 17 and int(d[2]) <= 23):  #Jan week 4\n",
    "                ls.append('2022-01-23')\n",
    "            elif (int(d[2]) >= 24 and int(d[2]) <= 30):  #Jan week 4\n",
    "                ls.append('2022-01-30')\n",
    "            elif (int(d[2]) == 31):  #Jan week 4\n",
    "                ls.append('2022-02-06')\n",
    "        \n",
    "        #February\n",
    "        elif int(d[1]) == 2: \n",
    "            \n",
    "            if (int(d[2]) >= 1 and int(d[2]) <= 6):  #Feb week 1\n",
    "                ls.append('2022-02-06')\n",
    "            elif (int(d[2]) >= 7 and int(d[2]) <= 13):  #Feb week 2\n",
    "                ls.append('2022-02-13')\n",
    "            elif (int(d[2]) >= 14 and int(d[2]) <= 20):  #Feb week 3\n",
    "                ls.append('2022-02-20')\n",
    "            elif (int(d[2]) >= 21 and int(d[2]) <= 27):  #Feb week 4\n",
    "                ls.append('2022-02-27')\n",
    "            elif (int(d[2]) == 28):  #Feb week 4\n",
    "                ls.append('2022-03-06')\n",
    "        \n",
    "        #March\n",
    "        elif int(d[1]) == 3:    \n",
    "            if (int(d[2]) >= 1 and int(d[2]) <= 6):  #March week 1\n",
    "                ls.append('2022-03-06')\n",
    "            elif (int(d[2]) >= 7 and int(d[2]) <= 13):  #March week 2\n",
    "                ls.append('2022-03-13')\n",
    "            elif (int(d[2]) >= 14 and int(d[2]) <= 20):  #March week 3\n",
    "                ls.append('2022-03-20')\n",
    "            elif (int(d[2]) >= 21 and int(d[2]) <= 27):  #March week 4\n",
    "                ls.append('2022-03-27')\n",
    "            elif (int(d[2]) >= 28 and int(d[2]) <= 31):  #March week 4\n",
    "                ls.append('2022-04-03')\n",
    "            \n",
    "        #April\n",
    "        elif int(d[1]) == 4:    \n",
    "            if (int(d[2]) >= 1 and int(d[2]) <= 3):  #April week 1\n",
    "                ls.append('2022-04-03')\n",
    "            elif (int(d[2]) >= 4 and int(d[2]) <= 10): #April week 2\n",
    "                ls.append('2022-04-10')\n",
    "            elif (int(d[2]) >= 11 and int(d[2]) <= 17): #April week 3\n",
    "                ls.append('2022-04-17')\n",
    "            elif (int(d[2]) >= 18 and int(d[2]) <= 24):  #April week 4\n",
    "                ls.append('2022-04-24')\n",
    "            elif (int(d[2]) >= 25 and int(d[2]) <= 30):  #April week 5\n",
    "                ls.append('2022-05-01')\n",
    "                \n",
    "        #May\n",
    "        elif int(d[1]) == 5:    \n",
    "            if (int(d[2]) >= 1 and int(d[2]) <= 1):  #May week 1\n",
    "                ls.append('2022-05-01')\n",
    "            elif (int(d[2]) >= 2 and int(d[2]) <=8): #May week 2\n",
    "                ls.append('2022-05-08')\n",
    "            elif (int(d[2]) >= 9 and int(d[2]) <= 15): #May week 3\n",
    "                ls.append('2022-05-15')\n",
    "            elif (int(d[2]) >= 16 and int(d[2]) <= 22):  #May week 4\n",
    "                ls.append('2022-05-22')\n",
    "            elif (int(d[2]) >= 23 and int(d[2]) <= 29):  #May week 5\n",
    "                ls.append('2022-05-29')\n",
    "            elif (int(d[2]) >= 30 and int(d[2]) <= 31):  #May week 5\n",
    "                ls.append('2022-06-05')\n",
    "        #June\n",
    "        elif int(d[1]) == 6:    \n",
    "            if (int(d[2]) >= 1 and int(d[2]) <= 5):  #June week 1\n",
    "                ls.append('2022-06-05')\n",
    "            elif (int(d[2]) >= 6 and int(d[2]) <=12): #June week 2\n",
    "                ls.append('2022-06-12')\n",
    "            elif (int(d[2]) >= 13 and int(d[2]) <= 19): #June week 3\n",
    "                ls.append('2022-06-19')\n",
    "            elif (int(d[2]) >= 20 and int(d[2]) <= 26):  #June week 4\n",
    "                ls.append('2022-06-26')\n",
    "            elif (int(d[2]) >= 27 and int(d[2]) <= 30):  #June week 5\n",
    "                ls.append('2022-07-03')\n",
    "                \n",
    "        #July\n",
    "        elif int(d[1]) == 7:    \n",
    "            if (int(d[2]) >= 1 and int(d[2]) <= 3):  #July week 1\n",
    "                ls.append('2022-07-03')\n",
    "            elif (int(d[2]) >= 4 and int(d[2]) <=10): #July week 2\n",
    "                ls.append('2022-07-10')\n",
    "            elif (int(d[2]) >= 11 and int(d[2]) <= 17): #July week 3\n",
    "                ls.append('2022-07-17')\n",
    "            elif (int(d[2]) >= 18 and int(d[2]) <= 24):  #July week 4\n",
    "                ls.append('2022-07-24')\n",
    "            elif (int(d[2]) >= 27 and int(d[2]) <= 31):  #July week 5\n",
    "                ls.append('2022-07-31')\n",
    "        \n",
    "        else:\n",
    "            ls.append('Wrong')        \n",
    "            \n",
    "df['WeekEnding']= pd.DataFrame(ls) #Adding Week ending to the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776ddd2c",
   "metadata": {},
   "source": [
    "# Reordering the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16097e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['WeekEnding','Date', 'QA_Name', 'Queue_Name', 'object_id', 'Handling_Time']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba119340",
   "metadata": {},
   "source": [
    "# Creating new columns (TL, Code, Market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d4b602e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path and doc with team codes\n",
    "df_tc = pd.read_excel(teamcode_rootdir)\n",
    "df = df.join(df_tc.set_index('QA')['TL'], on='QA_Name') # Adding TL\n",
    "df = df.join(df_tc.set_index('QA')['Code'], on='QA_Name') # Adding Code\n",
    "df = df.join(df_tc.set_index('QA')['Market'], on='QA_Name') # Adding Market\n",
    "df.fillna('Unmapped', inplace = True) # Controling null values due to lack of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48eb6a74",
   "metadata": {},
   "source": [
    "# Adding Column BPO and Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b8fde49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7663 entries, 0 to 7662\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Queue Name  7663 non-null   object\n",
      " 1   Queue ID    7663 non-null   int64 \n",
      " 2   Type        7663 non-null   object\n",
      " 3   BPO         4450 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 239.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#Path and doc with team codes\n",
    "df_qrd = pd.read_excel(queues_rootdir)\n",
    "df_qrd.info()\n",
    "df = df.join(df_qrd.set_index('Queue Name')['BPO'], on='Queue_Name') # Adding BPO\n",
    "df = df.join(df_qrd.set_index('Queue Name')['Type'], on='Queue_Name') # Adding Queue type\n",
    "df.fillna('Unmapped', inplace = True) # Controling null values due to lack of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f0c120",
   "metadata": {},
   "source": [
    "# Reshaping the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "066b5045",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'Date': 'date'\n",
    "                        , 'QA_Name': 'verifier'\n",
    "                        , 'Handling_Time': 'Handling_Time_Seconds'\n",
    "                        , 'Queue_Name': 'Queue Name'})\n",
    "df[\"timestamp\"] = \"\"\n",
    "df[\"hrt\"] = \"\"\n",
    "df[\"project_id\"] = \"\"\n",
    "df['WeekEnding'] = pd.to_datetime(df['WeekEnding'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1761234",
   "metadata": {},
   "source": [
    "# Exporting to excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32bf2ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(sql_rootdir,\n",
    "                        date_format='dd/mm/yyy',\n",
    "                        datetime_format='dd/mm/yyyy') as writer:\n",
    "    df.to_excel(writer, index=False, encoding='utf-8-sig', sheet_name= 'SQL - Raw Data')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29f4aeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1083 entries, 0 to 1082\n",
      "Data columns (total 14 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   WeekEnding             1083 non-null   datetime64[ns]\n",
      " 1   date                   1083 non-null   object        \n",
      " 2   verifier               1083 non-null   object        \n",
      " 3   Queue Name             1083 non-null   object        \n",
      " 4   object_id              1083 non-null   int64         \n",
      " 5   Handling_Time_Seconds  1083 non-null   float64       \n",
      " 6   TL                     1083 non-null   object        \n",
      " 7   Code                   1083 non-null   object        \n",
      " 8   Market                 1083 non-null   object        \n",
      " 9   BPO                    1083 non-null   object        \n",
      " 10  Type                   1083 non-null   object        \n",
      " 11  timestamp              1083 non-null   object        \n",
      " 12  hrt                    1083 non-null   object        \n",
      " 13  project_id             1083 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(11)\n",
      "memory usage: 118.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4615ddb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
